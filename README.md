# Governed AI Portfolio — Admission Control for Agentic Change

> **Positioning:** control-plane architecture for AI/agentic systems: admissibility, auditability, and governance-by-construction.

## Quick links
- Hiring TL;DR → `docs/01_HIRING_MANAGER_TLDR.md`
- 15-min evaluation path → `docs/02_15MIN_EVAL_PLAYBOOK.md`
- Evidence pack → `docs/08_EVIDENCE_PACK.md`
- ADL “boom” checklist (today/tomorrow) → `docs/09_ADL_BOOM_CHECKLIST.md`

---

## What this portfolio is (and is not)

> [!IMPORTANT]
> This is **not** a “projects gallery”. It is a **coherent trajectory** showing how responsibility escalates from signal → change governance → decision admissibility.

**This portfolio is:**
- A landing page for hiring loops (Staff/Principal/Architect) evaluating **governance, model risk, and agentic systems architecture**.
- A set of **falsifiable claims** with **evidence pointers**.

**This portfolio is not:**
- a SaaS pitch,
- a hype deck,
- a claim that autonomy is safe by default.

---

## The trajectory (coherent, not parachuted)
My path is deliberate:

**Economics → Risk management → Econometrics → Applied ML → Crypto decision systems → Change governance → Decision admissibility**

1) **Crypto Signals Ensemble** — signal + risk under uncertainty  
2) **DevTracker Governance** — governance as admission control for change; evidence boundary  
3) **Agentic Decision Ledger (ADL)** — decision contracts + commit-time admissibility (Decision ≠ Log)

Repos:
- Crypto Signals Ensemble: https://github.com/lexseasson/crypto_signals_ensemble
- DevTracker Governance: https://github.com/lexseasson/devtracker-governance
- Agentic Decision Ledger (ADL): https://github.com/lexseasson/agentic-decision-ledger

---

## Systems map (one diagram)
```mermaid
flowchart LR
  A[Crypto Signals Ensemble<br/>Signal + Risk Metrics + Reproducibility] --> B[DevTracker Governance<br/>Evidence Boundary + Audit Artifacts]
  B --> C[Agentic Decision Ledger (ADL)<br/>Decision Contracts + Commit-time Admissibility]

  subgraph Pressures[Production pressures]
    P1[Uncertainty & cost of error] --> A
    P2[Change velocity & organizational amnesia] --> B
    P3[Auditability, turnover, drift] --> C
  end

---

## The hook (what breaks in real orgs)
Agentic systems fail when:
- change ships without admissibility,
- automation overwrites meaning (semantics),
- evidence is missing when incidents happen,
- responsibility is ambiguous (“who approved this?”).

> **Thesis:** Governance is not bureaucracy — it is admission control for change.

---

## How to evaluate (fast)
Start here:
1) `docs/01_HIRING_MANAGER_TLDR.md` (90 seconds)
2) `docs/02_15MIN_EVAL_PLAYBOOK.md` (exact route)
3) `docs/08_EVIDENCE_PACK.md` (clickable proof)

---

## Role fit (explicit)
- AI Governance Architect
- Responsible AI Architect
- AI Risk Management / Model Risk AI
- LLM / Agentic Systems Architect
- Staff/Principal Platform Engineer (AI control-plane)

See: `docs/03_SYSTEMS_MAP.md` and `docs/04_ARCHITECTURE_AND_INNOVATION.md`
